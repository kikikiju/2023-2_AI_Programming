{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "pmBHwvnpx3zc",
        "omRzX0J2x6H4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Kobert.ipynb 와 DCGAN.ipynb에서 훈련한 모델들을 불러온다.  \n",
        "가중치만 저장했기 때문에 Model architecture는 선언해주어야한다.  \n",
        "따라서 필요한 라이브러리와 Pretrained model을 import한다."
      ],
      "metadata": {
        "id": "4tvMxG7kN4_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KOBERT"
      ],
      "metadata": {
        "id": "pmBHwvnpx3zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install mxnet\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "lD_K9IEiR30_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gluonnlp as nlp\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "from transformers import BertModel\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "gFd4p-u0smmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #GPU 사용"
      ],
      "metadata": {
        "id": "Y702JYYMtMEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6-mTZIeFttWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset을 정의하는 Class\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, vocab=vocab, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "metadata": {
        "id": "9JBCN1m3t3Fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
        "bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n",
        "vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower = False)"
      ],
      "metadata": {
        "id": "JW0Q7-Eqt6ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tok = tokenizer.tokenize"
      ],
      "metadata": {
        "id": "4Nd82B0Wt61q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KOBERT ARCHITECTURE"
      ],
      "metadata": {
        "id": "LisbTKYQuCgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes = 4,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "\n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "\n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "metadata": {
        "id": "QYMEtPV1t-NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyper parameter\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 10\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ],
      "metadata": {
        "id": "lGuwbyAbw7it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련한 모델 weight 불러오기\n",
        "filepath = '/content/drive/MyDrive/aipro/new_bert.pth'\n",
        "model_bert = BERTClassifier(bertmodel,dr_rate = 0.5)\n",
        "model_bert.load_state_dict(torch.load(filepath,map_location = torch.device('cpu')))"
      ],
      "metadata": {
        "id": "NK4WyaxhuLPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def new_softmax(a) :\n",
        "    c = np.max(a) # 최댓값\n",
        "    exp_a = np.exp(a-c) # 각각의 원소에 최댓값을 뺀 값에 exp를 취한다. (이를 통해 overflow 방지)\n",
        "    sum_exp_a = np.sum(exp_a)\n",
        "    y = (exp_a / sum_exp_a) * 100\n",
        "    return np.round(y, 3)\n",
        "\n",
        "def predict(predict_sentence): # 모델을 예측할 때, 입력으로 그냥 문장을 넣으면 안됨, Token화 된 문장을 넣어야하므로 Predict함수를 따로 정의하여 처리해주어야한다\n",
        "\n",
        "    data = [predict_sentence, '0']\n",
        "    dataset_another = [data]\n",
        "\n",
        "    another_test = BERTDataset(dataset_another, 0, 1, tok, vocab, max_len, True, False)\n",
        "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
        "\n",
        "    model_bert.eval()\n",
        "\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "\n",
        "        out = model_bert(token_ids, valid_length, segment_ids)\n",
        "\n",
        "\n",
        "        test_eval=[]\n",
        "        for i in out:\n",
        "            logits=i\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            min_v = min(logits)\n",
        "            total = 0\n",
        "            probability = []\n",
        "            logits = np.round(new_softmax(logits),3).tolist()\n",
        "            for logit in logits:\n",
        "                probability.append(np.round(logit,3))\n",
        "\n",
        "            if np.argmax(logits) == 0:\n",
        "                test_eval.append(\"분노\")\n",
        "            elif np.argmax(logits) == 1:\n",
        "                test_eval.append(\"슬픔\")\n",
        "            elif np.argmax(logits) == 2:\n",
        "                test_eval.append(\"불안\")\n",
        "            elif np.argmax(logits) == 3:\n",
        "                test_eval.append(\"행복\")\n",
        "            #print(probability)\n",
        "\n",
        "        return test_eval[0]"
      ],
      "metadata": {
        "id": "EHqwJgbOuc60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DCGAN"
      ],
      "metadata": {
        "id": "omRzX0J2x6H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transforms 정의하기\n",
        "h, w = 64, 64\n",
        "mean = (0.5, 0.5, 0.5)\n",
        "std = (0.5, 0.5, 0.5)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                    transforms.Resize((h,w)),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(mean, std)\n",
        "])"
      ],
      "metadata": {
        "id": "fKflLnYgyZdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파라미터 정의\n",
        "params = {'nz':100, # noise 수\n",
        "          'ngf':64, # generator에서 사용하는 conv filter 수\n",
        "          'ndf':64, # discriminator에서 사용하는 conv filter 수\n",
        "          'img_channel':3, # 이미지 채널\n",
        "          }"
      ],
      "metadata": {
        "id": "38aAVIuEycq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator: noise를 입력받아 가짜 이미지를 생성합니다.\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super().__init__()\n",
        "        nz = params['nz'] # noise 수, 100\n",
        "        ngf = params['ngf'] # conv filter 수\n",
        "        img_channel = params['img_channel'] # 이미지 채널\n",
        "\n",
        "        self.dconv1 = nn.ConvTranspose2d(nz,ngf*8,4, stride=1, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(ngf*8)\n",
        "        self.dconv2 = nn.ConvTranspose2d(ngf*8,ngf*4, 4, stride=2, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(ngf*4)\n",
        "        self.dconv3 = nn.ConvTranspose2d(ngf*4,ngf*2,4,stride=2,padding=1,bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(ngf*2)\n",
        "        self.dconv4 = nn.ConvTranspose2d(ngf*2,ngf,4,stride=2,padding=1,bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(ngf)\n",
        "        self.dconv5 = nn.ConvTranspose2d(ngf,img_channel,4,stride=2,padding=1,bias=False)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.bn1(self.dconv1(x)))\n",
        "        x = F.relu(self.bn2(self.dconv2(x)))\n",
        "        x = F.relu(self.bn3(self.dconv3(x)))\n",
        "        x = F.relu(self.bn4(self.dconv4(x)))\n",
        "        x = torch.tanh(self.dconv5(x))\n",
        "        return x\n",
        "\n",
        "# check\n",
        "x = torch.randn(1,100,1,1, device=device)\n",
        "model_gen = Generator(params).to(device)\n",
        "out_gen = model_gen(x)\n",
        "print(out_gen.shape)"
      ],
      "metadata": {
        "id": "4IB4NdKnyji7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator: 진짜 이미지와 가짜 이미지를 식별합니다.\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,params):\n",
        "        super().__init__()\n",
        "        img_channel = params['img_channel'] # 3\n",
        "        ndf = params['ndf'] # 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(img_channel,ndf,4,stride=2,padding=1,bias=False)\n",
        "        self.conv2 = nn.Conv2d(ndf,ndf*2,4,stride=2,padding=1,bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(ndf*2)\n",
        "        self.conv3 = nn.Conv2d(ndf*2,ndf*4,4,stride=2,padding=1,bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(ndf*4)\n",
        "        self.conv4 = nn.Conv2d(ndf*4,ndf*8,4,stride=2,padding=1,bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(ndf*8)\n",
        "        self.conv5 = nn.Conv2d(ndf*8,1,4,stride=1,padding=0,bias=False)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.leaky_relu(self.conv1(x),0.2)\n",
        "        x = F.leaky_relu(self.bn2(self.conv2(x)),0.2)\n",
        "        x = F.leaky_relu(self.bn3(self.conv3(x)),0.2)\n",
        "        x = F.leaky_relu(self.bn4(self.conv4(x)),0.2)\n",
        "        x = torch.sigmoid(self.conv5(x))\n",
        "        return x.view(-1,1)\n",
        "\n",
        "# check\n",
        "x = torch.randn(16,3,64,64,device=device)\n",
        "model_dis = Discriminator(params).to(device)\n",
        "out_dis = model_dis(x)\n",
        "print(out_dis.shape)"
      ],
      "metadata": {
        "id": "sGIz2dHYymGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 불러오기\n",
        "path2models = '/content/drive/MyDrive/aipro'\n",
        "path2weights_gen = os.path.join(path2models, 'weights_gen.pt')\n",
        "path2weights_dis = os.path.join(path2models, 'weights_dis.pt')\n",
        "\n",
        "weights = torch.load(path2weights_gen, map_location = torch.device('cpu'))\n",
        "model_gen.load_state_dict(weights)"
      ],
      "metadata": {
        "id": "9DSROaL9yv5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evalutaion mode\n",
        "model_gen.eval()"
      ],
      "metadata": {
        "id": "zUM7QN1JzUr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fake image 생성 test\n",
        "with torch.no_grad():\n",
        "    fixed_noise = torch.randn(1, 100,1,1, device=device)\n",
        "    label = torch.randint(0,10,(16,), device=device)\n",
        "    img_fake = model_gen(fixed_noise).detach().cpu()\n",
        "\n",
        "plt.imshow(to_pil_image(0.5*img_fake[0] + 0.5), cmap = 'gray')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "9a9zjmo2zLk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 시연"
      ],
      "metadata": {
        "id": "jjddg4D_1APs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "comfort_df = pd.read_csv('/content/drive/MyDrive/aipro/글귀.csv', encoding='cp949')\n",
        "comfort_df = comfort_df.dropna()\n",
        "\n",
        "def get_random_sentence(emotion):\n",
        "    return comfort_df[emotion].sample().iloc[0]\n",
        "\n",
        "def search_youtube(api_key, query, max_results=5):\n",
        "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "    # 검색 실행\n",
        "    search_response = youtube.search().list(\n",
        "        q=query,\n",
        "        type='video',\n",
        "        part='id,snippet',\n",
        "        maxResults=max_results\n",
        "    ).execute()\n",
        "\n",
        "    # 결과에서 동영상의 정보 추출\n",
        "    video_info = [{'title': item['snippet']['title'], 'videoId': item['id']['videoId']} for item in search_response['items']]\n",
        "\n",
        "    # 각 동영상의 주소와 제목 생성\n",
        "    results = [{'title': info['title'], 'url': f'https://www.youtube.com/watch?v={info[\"videoId\"]}'}\n",
        "               for info in video_info]\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # YouTube API 키를 설정\n",
        "    youtube_api_key = \"\"\n",
        "\n",
        "    print(\"안녕하세요! 저는 당신만의 감정분석AI 티미에요 ( ˃ ⩌˂)\\n\")\n",
        "    user_input = input(\"오늘 하루 기분은 어떠셨는지, 저에게 자유롭게 얘기해주세요!\\n\")\n",
        "    predicted_emotion = predict(user_input)\n",
        "\n",
        "    # 검색어를 입력\n",
        "    if(predicted_emotion == \"분노\"):\n",
        "        search_query = \"화날 때 듣기 좋은 음악\"\n",
        "        comfort_sentence = get_random_sentence(\"분노\")\n",
        "    elif(predicted_emotion == \"슬픔\"):\n",
        "        search_query = \"슬플 때 듣기 좋은 음악\"\n",
        "        comfort_sentence = get_random_sentence(\"슬픔\")\n",
        "    elif(predicted_emotion == \"불안\"):\n",
        "        search_query =  \"불안할 때 듣기 좋은 음악\"\n",
        "        comfort_sentence = get_random_sentence(\"불안\")\n",
        "    elif(predicted_emotion == \"행복\"):\n",
        "        search_query = \"기분 좋을 때 듣기 좋은 음악\"\n",
        "        comfort_sentence = \"행복\"\n",
        "\n",
        "    # YouTube API를 사용하여 동영상 주소 및 제목 가져오기\n",
        "    video_results = search_youtube(youtube_api_key, search_query)\n",
        "    # 결과 출력\n",
        "    if(comfort_sentence):\n",
        "        print(\"\\n현재 감정 상태가\",\"<\",predicted_emotion,\">\",\"이시네요.\")\n",
        "        print(\"\\n\",predicted_emotion,\"감정을 가진 당신을 위해 멋진 풍경 그림을 그려보았어요!\")\n",
        "        with torch.no_grad():\n",
        "            fixed_noise = torch.randn(1, 100,1,1, device=device)\n",
        "            label = torch.randint(0,10,(16,), device=device)\n",
        "            img_fake = model_gen(fixed_noise).detach().cpu()\n",
        "\n",
        "        plt.imshow(to_pil_image(0.5*img_fake[0] + 0.5), cmap = 'gray')\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        if(comfort_sentence != \"행복\"):\n",
        "            print(f\"\\n이 글귀를 읽고 마음을 다스려보는건 어떨까요? \\n=>{comfort_sentence}\\n\")\n",
        "        else:\n",
        "            print(\"\\n행복한 감정은 우리가 가진 잠재력을 충분히 발휘할 수 있게 도와주면서 우리의 삶을 더욱 풍요롭게 해줘요\\n\")\n",
        "            print(\"앞으로 세상을 살아가면서 슬프고,불안하고,화가나는 일들이 생기면, 차분히 눈을 감고 행복했던 일들을 떠올려보세요!\\n\")\n",
        "\n",
        "        print(f\"\\n{search_query} 플레이리스트를 추천해드릴게요\\n\")\n",
        "        for i, result in enumerate(video_results, start=1):\n",
        "            print(f\"{i}. {result['title']} \\n {result['url']} \\n\")\n",
        "\n",
        "comfort_sentence=\"\""
      ],
      "metadata": {
        "id": "y-hdHFIs1JQD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
