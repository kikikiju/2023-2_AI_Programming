{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감정분석 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 수집\n",
    "## 1-1. csv파일로 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>1번 감정</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>권태긴줄 알았는데 다른 사람이 생겼나보더라고.</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19369</th>\n",
       "      <td>나 엘리베이터에 갇혔어.</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19370</th>\n",
       "      <td>하지만 기분이 나쁜 걸 어떡해?</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19371</th>\n",
       "      <td>자취방 엘리베이턴데 정전인가봐.</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19372</th>\n",
       "      <td>나 드디어 프로젝트 끝났어!</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19373</th>\n",
       "      <td>걱정해줘서 고마워.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43991 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             발화문      1번 감정\n",
       "0               어, 청소 니가 대신 해 줘!    Neutral\n",
       "1             둘 다 청소 하기 싫어. 귀찮아.    Neutral\n",
       "2                 둘 다 하기 싫어서 화내.      Angry\n",
       "3                    그럼 방세는 어떡해.    Sadness\n",
       "4      권태긴줄 알았는데 다른 사람이 생겼나보더라고.    Sadness\n",
       "...                          ...        ...\n",
       "19369              나 엘리베이터에 갇혔어.  happiness\n",
       "19370          하지만 기분이 나쁜 걸 어떡해?    sadness\n",
       "19371          자취방 엘리베이턴데 정전인가봐.    sadness\n",
       "19372            나 드디어 프로젝트 끝났어!    disgust\n",
       "19373                 걱정해줘서 고마워.    neutral\n",
       "\n",
       "[43991 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('data/data-preprocess/data-1.csv', encoding='cp949')\n",
    "df2 = pd.read_csv('data/data-preprocess/data-2.csv', encoding='cp949')\n",
    "df3 = pd.read_csv('data/data-preprocess/data-3.csv', encoding='cp949')\n",
    "\n",
    "df = df = pd.concat([df1,df2,df3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'angry' 'sadness' 'disgust' 'surprise' 'fear' 'happiness']\n"
     ]
    }
   ],
   "source": [
    "df.loc[:, '1번 감정'] = df['1번 감정'].str.lower()\n",
    "unique_count = df['1번 감정'].unique()\n",
    "print(unique_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'sadness' 'disgust' 'surprise' 'fear' 'happiness']\n"
     ]
    }
   ],
   "source": [
    "df = df[df['1번 감정'] != 'neutral']\n",
    "unique_count = df['1번 감정'].unique()\n",
    "print(unique_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_copy = df.copy()\n",
    "\n",
    "#감정을 숫자로 매칭\n",
    "df_copy.loc[(df_copy['1번 감정'] == \"angry\"), '1번 감정'] = 0\n",
    "df_copy.loc[(df_copy['1번 감정'] == \"disgust\"), '1번 감정'] = 0\n",
    "df_copy.loc[(df_copy['1번 감정'] == \"sadness\"), '1번 감정'] = 1\n",
    "df_copy.loc[(df_copy['1번 감정'] == \"fear\"), '1번 감정'] = 2\n",
    "df_copy.loc[(df_copy['1번 감정'] == \"surprise\"), '1번 감정'] = 2\n",
    "df_copy.loc[(df_copy['1번 감정'] == \"happiness\"), '1번 감정'] = 3\n",
    "\n",
    "# 원래 df에 다시 넣어주고, 맨 왼쪽의 인덱스를 초기화해줌\n",
    "df.loc[:, '1번 감정'] = df_copy['1번 감정']\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>1번 감정</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>권태긴줄 알았는데 다른 사람이 생겼나보더라고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>오늘 헤어졌어.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32028</th>\n",
       "      <td>맞아. 나한테만 퉁명스럽고 일을 많이 시키더라고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32029</th>\n",
       "      <td>나 엘리베이터에 갇혔어.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32030</th>\n",
       "      <td>하지만 기분이 나쁜 걸 어떡해?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32031</th>\n",
       "      <td>자취방 엘리베이턴데 정전인가봐.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32032</th>\n",
       "      <td>나 드디어 프로젝트 끝났어!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32033 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                발화문 1번 감정\n",
       "0                    둘 다 하기 싫어서 화내.     0\n",
       "1                       그럼 방세는 어떡해.     1\n",
       "2         권태긴줄 알았는데 다른 사람이 생겼나보더라고.     1\n",
       "3      어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.     0\n",
       "4                          오늘 헤어졌어.     1\n",
       "...                             ...   ...\n",
       "32028   맞아. 나한테만 퉁명스럽고 일을 많이 시키더라고.     1\n",
       "32029                 나 엘리베이터에 갇혔어.     3\n",
       "32030             하지만 기분이 나쁜 걸 어떡해?     1\n",
       "32031             자취방 엘리베이턴데 정전인가봐.     1\n",
       "32032               나 드디어 프로젝트 끝났어!     0\n",
       "\n",
       "[32033 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df #df 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "target_list = []\n",
    "\n",
    "for q,  label in zip(df['발화문'], df['1번 감정']):\n",
    "    data_list.append(q)\n",
    "    target_list.append(label)\n",
    "\n",
    "distribute_data = data_list\n",
    "distribute_target = target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt=Okt()\n",
    "\n",
    "tokenized_data = []\n",
    "\n",
    "for s in distribute_data:\n",
    "    text_2 = [word for word, pos in okt.pos(s) if (pos != 'Punctuation') and (pos != 'Josa') and (pos != 'Adverb')] # 조사 또는 문장부호는 빼줌\n",
    "    if text_2:  # 빈 리스트가 아닌 경우에만 추가\n",
    "        tokenized_data.append(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('그럼', 'Adjective'), ('방', 'Noun'), ('세는', 'Verb'), ('어떡해', 'Adjective'), ('.', 'Punctuation')]\n",
      "그럼 방세는 어떡해.\n",
      "['그럼', '방', '세는', '어떡해']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(okt.pos(distribute_data[1]))\n",
    "print(distribute_data[1])\n",
    "print(tokenized_data[1])\n",
    "print(distribute_target[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 전체 데이터에 대한 단어 빈도수 계산\n",
    "word_counts = Counter(word for sentence in tokenized_data for word in sentence)\n",
    "\n",
    "# 빈도수에 따라 단어를 정렬\n",
    "sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 상위 N개의 단어로 단어 사전 만들기\n",
    "top_words = [word for word, count in sorted_words[:500]]\n",
    "word_to_index = {word: idx for idx, word in enumerate(top_words)}\n",
    "\n",
    "# 모든 데이터를 숫자로 변환\n",
    "num_tokenized_data = [[word_to_index.get(word, 0) for word in sentence] for sentence in tokenized_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나: 5575번\n",
      "안: 3853번\n",
      "내: 2431번\n",
      "것: 2381번\n",
      "거: 1940번\n",
      "들: 1931번\n",
      "또: 1903번\n",
      "같아: 1754번\n",
      "못: 1685번\n",
      "있어: 1683번\n",
      "친구: 1662번\n",
      "잘: 1521번\n",
      "지금: 1492번\n",
      "정말: 1469번\n",
      "어제: 1433번\n",
      "한: 1430번\n",
      "없어: 1417번\n",
      "집: 1382번\n",
      "사람: 1351번\n",
      "\t: 1226번\n",
      "회사: 1219번\n",
      "해피: 1180번\n",
      "진짜: 1167번\n",
      "응: 1104번\n",
      "그: 1053번\n",
      "아: 1037번\n",
      "아니: 1033번\n",
      "좀: 1029번\n",
      "시간: 1023번\n",
      "약속: 1019번\n",
      "했어: 967번\n",
      "청소: 958번\n",
      "해: 928번\n",
      "기분: 919번\n",
      "일: 918번\n",
      "할: 892번\n",
      "우리: 888번\n",
      "말: 875번\n",
      "애: 855번\n",
      "돼: 854번\n",
      "생각: 838번\n",
      "하는: 834번\n",
      "갑자기: 834번\n",
      "같: 801번\n",
      "어: 780번\n",
      "때: 778번\n",
      "화장실: 775번\n",
      "더: 772번\n",
      "봐: 770번\n",
      "왔어: 739번\n",
      "연락: 727번\n",
      "그냥: 727번\n",
      "했는데: 714번\n",
      "요즘: 708번\n",
      "면접: 707번\n",
      "마음: 693번\n",
      "거야: 690번\n",
      "고마워: 681번\n",
      "오늘: 674번\n",
      "일이: 673번\n",
      "그래: 668번\n",
      "술: 668번\n",
      "않아: 648번\n",
      "어떻게: 648번\n",
      "이: 641번\n",
      "때문: 634번\n",
      "다른: 626번\n",
      "좋은: 623번\n",
      "있는데: 592번\n",
      "됐어: 585번\n",
      "당첨: 578번\n",
      "냄새: 571번\n",
      "아빠: 562번\n",
      "왜: 556번\n",
      "나도: 546번\n",
      "곰팡이: 536번\n",
      "이제: 534번\n",
      "계속: 529번\n",
      "퇴근: 529번\n",
      "있어서: 526번\n",
      "자주: 523번\n",
      "얘기: 521번\n",
      "해야: 521번\n",
      "번: 506번\n",
      "세상: 506번\n",
      "하고: 500번\n",
      "다시: 496번\n",
      "떨어졌어: 496번\n",
      "뭐: 485번\n",
      "토: 480번\n",
      "모르겠어: 473번\n",
      "걱정: 471번\n",
      "다쳤어: 470번\n",
      "전화: 463번\n",
      "아무: 453번\n",
      "떠났어: 445번\n",
      "해도: 440번\n",
      "얼마나: 432번\n",
      "매일: 432번\n",
      "이번: 431번\n",
      "그런: 429번\n",
      "수: 428번\n",
      "이벤트: 424번\n",
      "너: 422번\n",
      "달: 421번\n",
      "헤어졌어: 418번\n",
      "우울해: 418번\n",
      "해서: 416번\n",
      "힘들어: 415번\n",
      "이야기: 415번\n",
      "수가: 409번\n",
      "밥: 408번\n",
      "새: 405번\n",
      "맞아: 404번\n",
      "병원: 403번\n",
      "프로젝트: 403번\n",
      "조금: 402번\n",
      "만: 401번\n",
      "짭: 401번\n",
      "깜짝: 400번\n",
      "허리: 397번\n",
      "준비: 394번\n",
      "혼자: 386번\n",
      "저녁: 386번\n",
      "하지만: 382번\n",
      "가족: 379번\n",
      "게: 375번\n",
      "비: 361번\n",
      "누가: 354번\n",
      "기획: 349번\n",
      "지진: 348번\n",
      "동안: 347번\n",
      "없나: 347번\n",
      "두: 346번\n",
      "무서웠어: 346번\n",
      "시작: 346번\n",
      "있는: 340번\n",
      "쓰레기통: 339번\n",
      "방: 337번\n",
      "그대로: 333번\n",
      "됐다고: 332번\n",
      "놀랐어: 332번\n",
      "된: 329번\n",
      "자꾸: 323번\n",
      "화가: 323번\n",
      "산책: 323번\n",
      "내일: 316번\n",
      "싸우게: 311번\n",
      "몸: 306번\n",
      "정도: 305번\n",
      "끝났어: 302번\n",
      "새끼: 301번\n",
      "쓰레기: 299번\n",
      "짜증나: 295번\n",
      "룸메이트: 293번\n",
      "주식: 293번\n",
      "될: 292번\n",
      "난: 291번\n",
      "들어: 290번\n",
      "그런데: 288번\n",
      "처음: 288번\n",
      "먹고: 287번\n",
      "싶어: 286번\n",
      "와: 281번\n",
      "해줘: 281번\n",
      "아까: 280번\n",
      "휴가: 278번\n",
      "기다리고: 277번\n",
      "곳: 275번\n",
      "유기견: 272번\n",
      "구경: 268번\n",
      "하나: 264번\n",
      "무서워: 264번\n",
      "벌레: 264번\n",
      "하는게: 263번\n",
      "갈: 263번\n",
      "보고: 261번\n",
      "매번: 261번\n",
      "하는데: 260번\n",
      "코로나: 259번\n",
      "축하: 259번\n",
      "부모님: 257번\n",
      "아니야: 257번\n",
      "받아: 256번\n",
      "상사: 255번\n",
      "전: 252번\n",
      "건: 249번\n",
      "날: 248번\n",
      "없고: 246번\n",
      "살: 245번\n",
      "룸메: 245번\n",
      "권태기: 244번\n",
      "벌써: 243번\n",
      "되었어: 243번\n",
      "역겨운: 242번\n",
      "드시고: 241번\n",
      "명: 241번\n",
      "말씀: 240번\n",
      "막: 239번\n",
      "음식물: 236번\n",
      "한지: 236번\n",
      "데: 236번\n",
      "일주일: 234번\n",
      "지: 234번\n",
      "짜장면: 234번\n",
      "마라톤: 233번\n",
      "완전: 228번\n",
      "나고: 228번\n",
      "좋아: 225번\n",
      "없어서: 224번\n",
      "항상: 223번\n",
      "없는: 220번\n",
      "속상해: 220번\n",
      "음악: 220번\n",
      "알: 218번\n",
      "헐: 218번\n",
      "짜증: 217번\n",
      "봤는데: 216번\n",
      "돼서: 214번\n",
      "향수: 214번\n",
      "기록: 214번\n",
      "적: 211번\n",
      "계단: 208번\n",
      "하니까: 207번\n",
      "줄: 206번\n",
      "하: 204번\n",
      "치웠어: 203번\n",
      "많아서: 203번\n",
      "없었어: 202번\n",
      "화: 202번\n",
      "다행히: 201번\n",
      "않고: 201번\n",
      "시키다가: 199번\n",
      "고등학교: 198번\n",
      "하지: 197번\n",
      "괜찮아: 197번\n",
      "였어: 196번\n",
      "우울한: 193번\n",
      "밤: 191번\n",
      "진행: 189번\n",
      "해줘서: 187번\n",
      "야근: 187번\n",
      "될까: 186번\n",
      "걸: 183번\n",
      "보: 181번\n",
      "당연히: 180번\n",
      "스트레스: 180번\n",
      "요새: 180번\n",
      "돈: 176번\n",
      "제: 176번\n",
      "알았어: 176번\n",
      "일도: 175번\n",
      "다섯: 174번\n",
      "몰라: 172번\n",
      "나서: 172번\n",
      "나갈: 171번\n",
      "새로운: 171번\n",
      "큰: 171번\n",
      "해봤지: 170번\n",
      "놀랬어: 170번\n",
      "의식: 169번\n",
      "그거: 169번\n",
      "마지막: 167번\n",
      "문제: 167번\n",
      "좋지: 167번\n",
      "싫어: 166번\n",
      "진정: 166번\n",
      "나왔어: 166번\n",
      "대회: 166번\n",
      "갇히게: 166번\n",
      "잘못: 165번\n",
      "사과: 164번\n",
      "주변: 164번\n",
      "있었어: 162번\n",
      "추천: 162번\n",
      "소리: 161번\n",
      "강아지: 161번\n",
      "한번: 160번\n",
      "그게: 160번\n",
      "다음: 160번\n",
      "힘: 157번\n",
      "있지: 156번\n",
      "와서: 155번\n",
      "해야지: 154번\n",
      "가서: 153번\n",
      "물: 152번\n",
      "주: 152번\n",
      "하면: 151번\n",
      "줄이: 151번\n",
      "물이: 150번\n",
      "완전히: 150번\n",
      "잠깐: 149번\n",
      "3년: 148번\n",
      "망했어: 148번\n",
      "일찍: 146번\n",
      "밖: 146번\n",
      "거기: 144번\n",
      "가: 144번\n",
      "볼: 144번\n",
      "응급실: 143번\n",
      "목: 143번\n",
      "않았어: 142번\n",
      "발목: 138번\n",
      "생긴: 138번\n",
      "입원: 138번\n",
      "다큐멘터리: 138번\n",
      "힘들: 136번\n",
      "않아서: 136번\n",
      "가지: 135번\n",
      "며칠: 134번\n",
      "제출: 134번\n",
      "별로: 133번\n",
      "무슨: 133번\n",
      "나가서: 133번\n",
      "이해: 132번\n",
      "하더라고: 131번\n",
      "해봤는데: 130번\n",
      "있으니까: 130번\n",
      "잠: 130번\n",
      "선물: 130번\n",
      "했지: 129번\n",
      "싸운: 129번\n",
      "욕: 129번\n",
      "다치셨어: 129번\n",
      "이런: 129번\n",
      "엄마: 128번\n",
      "갔다: 128번\n",
      "힘들고: 128번\n",
      "확: 127번\n",
      "싶은데: 126번\n",
      "아픈: 126번\n",
      "서: 126번\n",
      "갇힌: 126번\n",
      "엉망: 125번\n",
      "사진: 125번\n",
      "경찰: 125번\n",
      "달리는: 124번\n",
      "그럼: 123번\n",
      "어떡하지: 123번\n",
      "하루: 123번\n",
      "얼른: 123번\n",
      "바로: 123번\n",
      "드렸어: 122번\n",
      "그저께: 121번\n",
      "뽑는: 121번\n",
      "안해: 120번\n",
      "남자친구: 120번\n",
      "됐는데: 120번\n",
      "떨어지고: 120번\n",
      "업무: 120번\n",
      "놀라서: 118번\n",
      "꼭: 118번\n",
      "갱신: 118번\n",
      "하면서: 117번\n",
      "거의: 117번\n",
      "영상: 117번\n",
      "환기: 117번\n",
      "있었는데: 116번\n",
      "자고: 116번\n",
      "자다가: 116번\n",
      "아침: 115번\n",
      "강남: 115번\n",
      "가고: 114번\n",
      "드셔: 114번\n",
      "식당: 114번\n",
      "바빠서: 114번\n",
      "책임감: 114번\n",
      "좋아하는: 114번\n",
      "몰려: 114번\n",
      "그것: 112번\n",
      "였는데: 112번\n",
      "들어서: 112번\n",
      "궁금해서: 112번\n",
      "그러게: 111번\n",
      "혼났어: 111번\n",
      "아니고: 111번\n",
      "력: 111번\n",
      "도착: 111번\n",
      "광고: 111번\n",
      "얘: 110번\n",
      "진자: 110번\n",
      "괜찮은데: 109번\n",
      "자기: 109번\n",
      "무기: 109번\n",
      "있을까: 109번\n",
      "더러워: 108번\n",
      "고민: 108번\n",
      "중이: 107번\n",
      "이직: 107번\n",
      "왔다고: 107번\n",
      "장례: 107번\n",
      "서로: 107번\n",
      "치료: 107번\n",
      "결승선: 107번\n",
      "좋았어: 106번\n",
      "입맛: 105번\n",
      "한데: 105번\n",
      "당장: 105번\n",
      "상황: 105번\n",
      "온: 105번\n",
      "순간: 105번\n",
      "거지: 104번\n",
      "갖고: 104번\n",
      "노트북: 104번\n",
      "지장: 103번\n",
      "원래: 103번\n",
      "아주: 103번\n",
      "동창: 102번\n",
      "몰랐어: 102번\n",
      "구: 102번\n",
      "되고: 102번\n",
      "은: 101번\n",
      "층: 101번\n",
      "죽겠어: 100번\n",
      "버렸어: 100번\n",
      "여행: 100번\n",
      "실망: 100번\n",
      "종일: 100번\n",
      "났어: 99번\n",
      "되는: 99번\n",
      "없으면: 99번\n",
      "지치고: 99번\n",
      "엘리베이터: 99번\n",
      "그럴: 98번\n",
      "크게: 98번\n",
      "2: 98번\n",
      "하기: 97번\n",
      "생겼어: 97번\n",
      "난리: 97번\n",
      "같아서: 97번\n",
      "없어져: 97번\n",
      "손해: 97번\n",
      "그렇지: 96번\n",
      "알겠어: 96번\n",
      "천둥: 96번\n",
      "신나는: 96번\n",
      "되는데: 95번\n",
      "같은데: 95번\n",
      "걔: 95번\n",
      "앞: 95번\n",
      "15년: 95번\n",
      "여기저기: 95번\n",
      "뭐라고: 95번\n",
      "통과: 95번\n",
      "나를: 95번\n",
      "언: 95번\n",
      "동네: 95번\n",
      "거제: 95번\n",
      "최근: 94번\n",
      "수도: 94번\n",
      "나중: 94번\n",
      "싶었던: 94번\n",
      "계셔: 93번\n",
      "걷고: 93번\n",
      "봤지: 93번\n",
      "힘들어서: 93번\n",
      "중: 93번\n",
      "째: 93번\n",
      "아파: 93번\n",
      "뒷: 93번\n",
      "야: 92번\n",
      "없는데: 92번\n",
      "생명: 91번\n",
      "다친: 91번\n",
      "님: 91번\n",
      "답답해서: 91번\n",
      "예전: 91번\n",
      "가도: 91번\n",
      "아이: 91번\n",
      "방법: 90번\n",
      "간: 90번\n",
      "될지: 90번\n",
      "할게: 90번\n",
      "방향: 90번\n",
      "포기: 89번\n",
      "좋을: 89번\n",
      "인: 89번\n",
      "플루: 89번\n",
      "옆: 88번\n",
      "먹는데: 88번\n",
      "눈치: 88번\n",
      "버린: 87번\n",
      "다치진: 86번\n",
      "쉬: 86번\n",
      "마시고: 86번\n",
      "속이: 86번\n",
      "늦어: 86번\n",
      "더럽게: 85번\n",
      "하겠어: 85번\n",
      "이었어: 85번\n",
      "싶다: 85번\n",
      "만날: 85번\n",
      "오고: 85번\n",
      "효과: 85번\n",
      "기다리는데: 84번\n",
      "신경: 84번\n",
      "받고: 84번\n",
      "갇혔어: 84번\n",
      "위로: 83번\n",
      "그리고: 83번\n"
     ]
    }
   ],
   "source": [
    "# 상위 500개의 단어 선택\n",
    "top_words = [word for word, count in word_counts.most_common(500)]\n",
    "\n",
    "# 상위 500개의 단어에 대한 빈도수 출력\n",
    "for word in top_words:\n",
    "    print(f'{word}: {word_counts[word]}번')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 426, 0, 0], [337, 138, 0, 0], [0, 0, 0, 66, 18, 0, 0], [44, 233, 407, 487, 0, 408], [58, 105], [154, 80, 147, 39], [0, 329, 0, 65, 423, 110, 16], [64, 20, 99, 0, 262, 20, 236], [26, 395, 16], [23, 0, 0]]\n",
      "[0, 1, 1, 0, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(num_tokenized_data[0:10])\n",
    "print(distribute_target[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.345924515343552 7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "lengths = np.array([len(x) for x in num_tokenized_data])\n",
    "print(np.mean(lengths), np.median(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(lengths)\n",
    "plt.xlabel(\"length\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32033, 8)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_seq = pad_sequences(num_tokenized_data, maxlen = 8)\n",
    "\n",
    "print(train_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(train_seq, distribute_target, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, val_input, train_target, val_target = train_test_split(train_input, train_target, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20500, 8)\n",
      "(5126, 8)\n",
      "(6407, 8)\n",
      "(20500,)\n",
      "(5126,)\n",
      "(6407,)\n"
     ]
    }
   ],
   "source": [
    "train_target = np.array(train_target)\n",
    "val_target = np.array(val_target)\n",
    "test_target = np.array(test_target)\n",
    "\n",
    "print(train_input.shape)\n",
    "print(val_input.shape)\n",
    "print(test_input.shape)\n",
    "\n",
    "print(train_target.shape)\n",
    "print(val_target.shape)\n",
    "print(test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. 모델\n",
    "\n",
    "## 2-1. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "321/321 [==============================] - 7s 14ms/step - loss: 1.1806 - accuracy: 0.4845 - val_loss: 1.2041 - val_accuracy: 0.4557\n",
      "Epoch 2/80\n",
      "321/321 [==============================] - 4s 13ms/step - loss: 1.0105 - accuracy: 0.5798 - val_loss: 1.0086 - val_accuracy: 0.5962\n",
      "Epoch 3/80\n",
      "321/321 [==============================] - 5s 14ms/step - loss: 0.9483 - accuracy: 0.6129 - val_loss: 0.9226 - val_accuracy: 0.6284\n",
      "Epoch 4/80\n",
      "321/321 [==============================] - 7s 20ms/step - loss: 0.9066 - accuracy: 0.6323 - val_loss: 0.8812 - val_accuracy: 0.6395\n",
      "Epoch 5/80\n",
      "321/321 [==============================] - 6s 19ms/step - loss: 0.8718 - accuracy: 0.6503 - val_loss: 0.8541 - val_accuracy: 0.6627\n",
      "Epoch 6/80\n",
      "321/321 [==============================] - 6s 17ms/step - loss: 0.8492 - accuracy: 0.6589 - val_loss: 0.8323 - val_accuracy: 0.6740\n",
      "Epoch 7/80\n",
      "321/321 [==============================] - 6s 17ms/step - loss: 0.8265 - accuracy: 0.6689 - val_loss: 0.8558 - val_accuracy: 0.6791\n",
      "Epoch 8/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.8061 - accuracy: 0.6828 - val_loss: 0.8232 - val_accuracy: 0.6594\n",
      "Epoch 9/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.7921 - accuracy: 0.6898 - val_loss: 0.8068 - val_accuracy: 0.6797\n",
      "Epoch 10/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.7726 - accuracy: 0.6968 - val_loss: 0.8112 - val_accuracy: 0.6877\n",
      "Epoch 11/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.7677 - accuracy: 0.6967 - val_loss: 0.7775 - val_accuracy: 0.7041\n",
      "Epoch 12/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.7571 - accuracy: 0.7046 - val_loss: 0.7726 - val_accuracy: 0.7013\n",
      "Epoch 13/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.7501 - accuracy: 0.7043 - val_loss: 0.8144 - val_accuracy: 0.6742\n",
      "Epoch 14/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.7405 - accuracy: 0.7110 - val_loss: 0.7894 - val_accuracy: 0.6834\n",
      "Epoch 15/80\n",
      "321/321 [==============================] - 5s 15ms/step - loss: 0.7324 - accuracy: 0.7132 - val_loss: 0.8789 - val_accuracy: 0.6327\n",
      "Epoch 16/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.7329 - accuracy: 0.7118 - val_loss: 0.7875 - val_accuracy: 0.6886\n",
      "Epoch 17/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.7233 - accuracy: 0.7156 - val_loss: 0.7768 - val_accuracy: 0.6984\n",
      "Epoch 18/80\n",
      "321/321 [==============================] - 5s 15ms/step - loss: 0.7174 - accuracy: 0.7182 - val_loss: 0.7772 - val_accuracy: 0.7013\n",
      "Epoch 19/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.7136 - accuracy: 0.7221 - val_loss: 0.7590 - val_accuracy: 0.7068\n",
      "Epoch 20/80\n",
      "321/321 [==============================] - 6s 17ms/step - loss: 0.7073 - accuracy: 0.7243 - val_loss: 0.8031 - val_accuracy: 0.6826\n",
      "Epoch 21/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.7099 - accuracy: 0.7215 - val_loss: 0.7546 - val_accuracy: 0.7126\n",
      "Epoch 22/80\n",
      "321/321 [==============================] - 6s 18ms/step - loss: 0.7076 - accuracy: 0.7213 - val_loss: 0.7501 - val_accuracy: 0.7060\n",
      "Epoch 23/80\n",
      "321/321 [==============================] - 6s 18ms/step - loss: 0.6995 - accuracy: 0.7262 - val_loss: 0.7881 - val_accuracy: 0.7007\n",
      "Epoch 24/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.6981 - accuracy: 0.7239 - val_loss: 0.7786 - val_accuracy: 0.6939\n",
      "Epoch 25/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.6990 - accuracy: 0.7260 - val_loss: 0.7572 - val_accuracy: 0.7085\n",
      "Epoch 26/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.6969 - accuracy: 0.7259 - val_loss: 0.8610 - val_accuracy: 0.6483\n",
      "Epoch 27/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.6910 - accuracy: 0.7298 - val_loss: 0.7886 - val_accuracy: 0.7035\n",
      "Epoch 28/80\n",
      "321/321 [==============================] - 6s 18ms/step - loss: 0.6903 - accuracy: 0.7310 - val_loss: 0.7749 - val_accuracy: 0.7007\n",
      "Epoch 29/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.6925 - accuracy: 0.7272 - val_loss: 0.8316 - val_accuracy: 0.6758\n",
      "Epoch 30/80\n",
      "321/321 [==============================] - 6s 17ms/step - loss: 0.6867 - accuracy: 0.7326 - val_loss: 0.7773 - val_accuracy: 0.6939\n",
      "Epoch 31/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.6859 - accuracy: 0.7306 - val_loss: 0.7679 - val_accuracy: 0.7056\n",
      "Epoch 32/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.6843 - accuracy: 0.7314 - val_loss: 0.7402 - val_accuracy: 0.7162\n",
      "Epoch 33/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.6831 - accuracy: 0.7326 - val_loss: 0.7587 - val_accuracy: 0.6963\n",
      "Epoch 34/80\n",
      "321/321 [==============================] - 6s 17ms/step - loss: 0.6791 - accuracy: 0.7349 - val_loss: 0.7473 - val_accuracy: 0.7142\n",
      "Epoch 35/80\n",
      "321/321 [==============================] - 6s 17ms/step - loss: 0.6800 - accuracy: 0.7310 - val_loss: 0.7540 - val_accuracy: 0.7163\n",
      "Epoch 36/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.6792 - accuracy: 0.7313 - val_loss: 0.7780 - val_accuracy: 0.6888\n",
      "Epoch 37/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.6803 - accuracy: 0.7309 - val_loss: 0.8701 - val_accuracy: 0.6635\n",
      "Epoch 38/80\n",
      "321/321 [==============================] - 6s 18ms/step - loss: 0.6777 - accuracy: 0.7358 - val_loss: 0.7655 - val_accuracy: 0.7013\n",
      "Epoch 39/80\n",
      "321/321 [==============================] - 6s 17ms/step - loss: 0.6804 - accuracy: 0.7346 - val_loss: 0.7330 - val_accuracy: 0.7185\n",
      "Epoch 40/80\n",
      "321/321 [==============================] - 6s 19ms/step - loss: 0.6787 - accuracy: 0.7361 - val_loss: 0.7347 - val_accuracy: 0.7162\n",
      "Epoch 41/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.6755 - accuracy: 0.7371 - val_loss: 0.7396 - val_accuracy: 0.7189\n",
      "Epoch 42/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.6735 - accuracy: 0.7363 - val_loss: 0.7613 - val_accuracy: 0.7152\n",
      "Epoch 43/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.6750 - accuracy: 0.7355 - val_loss: 0.7467 - val_accuracy: 0.7183\n",
      "Epoch 44/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.6748 - accuracy: 0.7354 - val_loss: 0.7629 - val_accuracy: 0.6974\n",
      "Epoch 45/80\n",
      "321/321 [==============================] - 6s 18ms/step - loss: 0.6726 - accuracy: 0.7351 - val_loss: 0.7250 - val_accuracy: 0.7206\n",
      "Epoch 46/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.6710 - accuracy: 0.7350 - val_loss: 0.7291 - val_accuracy: 0.7185\n",
      "Epoch 47/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.6693 - accuracy: 0.7375 - val_loss: 0.7520 - val_accuracy: 0.7126\n",
      "Epoch 48/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.6666 - accuracy: 0.7380 - val_loss: 0.7563 - val_accuracy: 0.6996\n",
      "Epoch 49/80\n",
      "321/321 [==============================] - 6s 17ms/step - loss: 0.6697 - accuracy: 0.7368 - val_loss: 0.7364 - val_accuracy: 0.7179\n",
      "Epoch 50/80\n",
      "321/321 [==============================] - 6s 18ms/step - loss: 0.6690 - accuracy: 0.7391 - val_loss: 0.7938 - val_accuracy: 0.6883\n",
      "Epoch 51/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.6692 - accuracy: 0.7370 - val_loss: 0.7371 - val_accuracy: 0.7208\n",
      "Epoch 52/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.6671 - accuracy: 0.7384 - val_loss: 0.7805 - val_accuracy: 0.6939\n",
      "Epoch 53/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.6650 - accuracy: 0.7393 - val_loss: 0.7560 - val_accuracy: 0.7132\n",
      "Epoch 54/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.6660 - accuracy: 0.7397 - val_loss: 0.8177 - val_accuracy: 0.6859\n",
      "Epoch 55/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.6636 - accuracy: 0.7391 - val_loss: 0.7271 - val_accuracy: 0.7247\n",
      "Epoch 56/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.6608 - accuracy: 0.7380 - val_loss: 0.7999 - val_accuracy: 0.6890\n",
      "Epoch 57/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.6656 - accuracy: 0.7381 - val_loss: 1.1110 - val_accuracy: 0.5973\n",
      "Epoch 58/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.6652 - accuracy: 0.7387 - val_loss: 0.7277 - val_accuracy: 0.7240\n",
      "Epoch 59/80\n",
      "321/321 [==============================] - 5s 17ms/step - loss: 0.6619 - accuracy: 0.7398 - val_loss: 0.7451 - val_accuracy: 0.7160\n",
      "Epoch 60/80\n",
      "321/321 [==============================] - 5s 16ms/step - loss: 0.6613 - accuracy: 0.7382 - val_loss: 0.8050 - val_accuracy: 0.6883\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# 모델 정의\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=500, output_dim=128, input_length=8))\n",
    "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4, activation='softmax')) # 클래스의 개수에 맞게 설정\n",
    "\n",
    "# 모델 컴파일\n",
    "optimizer = SGD(learning_rate=0.005)\n",
    "model.compile(optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 콜백 정의\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-embedding-model.h5', save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(train_input, train_target, epochs=80, batch_size=64,\n",
    "                    validation_data=(val_input, val_target),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6952 - accuracy: 0.7383\n",
      "Test Loss: 0.6951923370361328\n",
      "Test Accuracy: 0.7382550239562988\n"
     ]
    }
   ],
   "source": [
    "# 패딩이 완료된 테스트 데이터\n",
    "test_input = pad_sequences(test_input, maxlen=8)\n",
    "\n",
    "loss, accuracy = model.evaluate(test_input, test_target)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3. 문장에서 감정분석 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 365ms/step\n",
      "입력 문장: 아 존나 힘들다\n",
      "예측된 감정: 분노\n",
      "각 클래스의 확률: [0.41666287 0.3910993  0.15109624 0.04114154]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "입력 문장: 씨발 개같다 그만 둘래\n",
      "예측된 감정: 슬픔\n",
      "각 클래스의 확률: [0.28495836 0.4504039  0.16031863 0.10431907]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "입력 문장: 진짜 너무하다 너\n",
      "예측된 감정: 분노\n",
      "각 클래스의 확률: [0.42040607 0.15896325 0.23334064 0.18729001]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "입력 문장: 그래도 너가 있어서 좋아\n",
      "예측된 감정: 기쁨\n",
      "각 클래스의 확률: [0.01357527 0.02505132 0.01729299 0.9440805 ]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "입력 문장: 내일 시험 봐서 너무 불안해\n",
      "예측된 감정: 불안\n",
      "각 클래스의 확률: [0.04506565 0.27138492 0.50351095 0.18003854]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# Assuming 'model' and 'word_to_index' are defined before this code\n",
    "\n",
    "# Load the Okt tokenizer\n",
    "okt = Okt()\n",
    "\n",
    "while True:\n",
    "    # 입력 문장\n",
    "    input_sentence = input()\n",
    "\n",
    "    # 종료 조건 확인\n",
    "    if input_sentence == '0':\n",
    "        break\n",
    "\n",
    "    # 입력 문장 토큰화 및 패딩\n",
    "    input_tokens = [word for word, pos in okt.pos(input_sentence) if (pos != 'Punctuation') and (pos != 'Josa') and (pos != 'Adverb')]\n",
    "    input_indices = [word_to_index.get(word, 0) for word in input_tokens]\n",
    "    padded_input = pad_sequences([input_indices], maxlen=8)\n",
    "\n",
    "    # 모델 예측\n",
    "    predicted_probabilities = model.predict(padded_input)\n",
    "    predicted_class = np.argmax(predicted_probabilities)\n",
    "\n",
    "    # 예측된 결과 출력\n",
    "    emotions = ['분노', '슬픔', '불안', '기쁨']\n",
    "    predicted_emotion = emotions[predicted_class]\n",
    "\n",
    "    print(f\"입력 문장: {input_sentence}\")\n",
    "    print(f\"예측된 감정: {predicted_emotion}\")\n",
    "    print(f\"각 클래스의 확률: {predicted_probabilities[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
