{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uhIDRamrg3W"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qZGwDw8EsJmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# transforms 정의하기\n",
        "h, w = 64, 64\n",
        "mean = (0.5, 0.5, 0.5)\n",
        "std = (0.5, 0.5, 0.5)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                    transforms.Resize((h,w)),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(mean, std)\n",
        "])"
      ],
      "metadata": {
        "id": "idvbj6HOsQ-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(root)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root, self.images[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n"
      ],
      "metadata": {
        "id": "snswZFa0tHCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "dataset = ImageDataset(root='/content/drive/MyDrive/aipro/dataset', transform= transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "ZhAqggC7tPSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파라미터 정의\n",
        "params = {'nz':100, # noise 수\n",
        "          'ngf':64, # generator에서 사용하는 conv filter 수\n",
        "          'ndf':64, # discriminator에서 사용하는 conv filter 수\n",
        "          'img_channel':3, # 이미지 채널\n",
        "          }"
      ],
      "metadata": {
        "id": "0zqZTKVQ4GIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator: noise를 입력받아 가짜 이미지를 생성합니다.\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super().__init__()\n",
        "        nz = params['nz'] # noise 수, 100\n",
        "        ngf = params['ngf'] # conv filter 수\n",
        "        img_channel = params['img_channel'] # 이미지 채널\n",
        "\n",
        "        self.dconv1 = nn.ConvTranspose2d(nz,ngf*8,4, stride=1, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(ngf*8)\n",
        "        self.dconv2 = nn.ConvTranspose2d(ngf*8,ngf*4, 4, stride=2, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(ngf*4)\n",
        "        self.dconv3 = nn.ConvTranspose2d(ngf*4,ngf*2,4,stride=2,padding=1,bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(ngf*2)\n",
        "        self.dconv4 = nn.ConvTranspose2d(ngf*2,ngf,4,stride=2,padding=1,bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(ngf)\n",
        "        self.dconv5 = nn.ConvTranspose2d(ngf,img_channel,4,stride=2,padding=1,bias=False)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.bn1(self.dconv1(x)))\n",
        "        x = F.relu(self.bn2(self.dconv2(x)))\n",
        "        x = F.relu(self.bn3(self.dconv3(x)))\n",
        "        x = F.relu(self.bn4(self.dconv4(x)))\n",
        "        x = torch.tanh(self.dconv5(x))\n",
        "        return x\n",
        "\n",
        "# check\n",
        "x = torch.randn(1,100,1,1, device=device)\n",
        "model_gen = Generator(params).to(device)\n",
        "out_gen = model_gen(x)\n",
        "print(out_gen.shape)\n"
      ],
      "metadata": {
        "id": "mTgbZuvC4Jmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator: 진짜 이미지와 가짜 이미지를 식별합니다.\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,params):\n",
        "        super().__init__()\n",
        "        img_channel = params['img_channel'] # 3\n",
        "        ndf = params['ndf'] # 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(img_channel,ndf,4,stride=2,padding=1,bias=False)\n",
        "        self.conv2 = nn.Conv2d(ndf,ndf*2,4,stride=2,padding=1,bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(ndf*2)\n",
        "        self.conv3 = nn.Conv2d(ndf*2,ndf*4,4,stride=2,padding=1,bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(ndf*4)\n",
        "        self.conv4 = nn.Conv2d(ndf*4,ndf*8,4,stride=2,padding=1,bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(ndf*8)\n",
        "        self.conv5 = nn.Conv2d(ndf*8,1,4,stride=1,padding=0,bias=False)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.leaky_relu(self.conv1(x),0.2)\n",
        "        x = F.leaky_relu(self.bn2(self.conv2(x)),0.2)\n",
        "        x = F.leaky_relu(self.bn3(self.conv3(x)),0.2)\n",
        "        x = F.leaky_relu(self.bn4(self.conv4(x)),0.2)\n",
        "        x = torch.sigmoid(self.conv5(x))\n",
        "        return x.view(-1,1)\n",
        "\n",
        "# check\n",
        "x = torch.randn(16,3,64,64,device=device)\n",
        "model_dis = Discriminator(params).to(device)\n",
        "out_dis = model_dis(x)\n",
        "print(out_dis.shape)\n"
      ],
      "metadata": {
        "id": "J_fir7b04QRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 초기화\n",
        "def initialize_weights(model):\n",
        "    classname = model.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(model.bias.data, 0)\n",
        "\n",
        "# 가중치 초기화 적용\n",
        "model_gen.apply(initialize_weights);\n",
        "model_dis.apply(initialize_weights);"
      ],
      "metadata": {
        "id": "XPvm3nZl4WCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수 정의\n",
        "loss_func = nn.BCELoss()\n",
        "\n",
        "# 최적화 함수\n",
        "from torch import optim\n",
        "lr = 2e-4\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "\n",
        "opt_dis = optim.Adam(model_dis.parameters(),lr=lr,betas=(beta1,beta2))\n",
        "opt_gen = optim.Adam(model_gen.parameters(),lr=lr,betas=(beta1,beta2))\n"
      ],
      "metadata": {
        "id": "ToFnZS7s4Wx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_gen.train()\n",
        "model_dis.train()\n",
        "\n",
        "batch_count=0\n",
        "num_epochs=200\n",
        "start_time = time.time()\n",
        "nz = params['nz'] # 노이즈 수 100\n",
        "loss_hist = {'dis':[],\n",
        "             'gen':[]}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for xb in dataloader:\n",
        "        ba_si = xb.shape[0]\n",
        "\n",
        "        xb = xb.to(device)\n",
        "        yb_real = torch.Tensor(ba_si,1).fill_(1.0).to(device)\n",
        "        yb_fake = torch.Tensor(ba_si,1).fill_(0.0).to(device)\n",
        "\n",
        "        # generator\n",
        "        model_gen.zero_grad()\n",
        "        z = torch.randn(ba_si,nz,1,1).to(device) # noise\n",
        "        out_gen = model_gen(z) # 가짜 이미지 생성\n",
        "        out_dis = model_dis(out_gen) # 가짜 이미지 식별\n",
        "\n",
        "        g_loss = loss_func(out_dis,yb_real)\n",
        "        g_loss.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "        # discriminator\n",
        "        model_dis.zero_grad()\n",
        "        out_dis = model_dis(xb) # 진짜 이미지 식별\n",
        "        loss_real = loss_func(out_dis,yb_real)\n",
        "\n",
        "        out_dis = model_dis(out_gen.detach()) # 가짜 이미지 식별\n",
        "        loss_fake = loss_func(out_dis,yb_fake)\n",
        "\n",
        "        d_loss = (loss_real + loss_fake) / 2\n",
        "        d_loss.backward()\n",
        "        opt_dis.step()\n",
        "\n",
        "        loss_hist['gen'].append(g_loss.item())\n",
        "        loss_hist['dis'].append(d_loss.item())\n",
        "\n",
        "        batch_count += 1\n",
        "        if batch_count % 64 == 0:\n",
        "            print('Epoch: %.0f, G_Loss: %.6f, D_Loss: %.6f, time: %.2f min' %(epoch, g_loss.item(), d_loss.item(), (time.time()-start_time)/60))"
      ],
      "metadata": {
        "id": "jcnVEEeA4bwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss history\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title('Loss Progress')\n",
        "plt.plot(loss_hist['gen'], label='Gen. Loss')\n",
        "plt.plot(loss_hist['dis'], label='Dis. Loss')\n",
        "plt.xlabel('batch count')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M8E_cFqUaNPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 저장\n",
        "path2models = '/content/drive/MyDrive/aipro'\n",
        "path2weights_gen = os.path.join(path2models, 'weights_gen.pt')\n",
        "path2weights_dis = os.path.join(path2models, 'weights_dis.pt')\n",
        "\n",
        "#torch.save(model_gen.state_dict(), path2weights_gen)\n",
        "#torch.save(model_dis.state_dict(), path2weights_dis)"
      ],
      "metadata": {
        "id": "9qP1iLc_Zkzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 불러오기\n",
        "weights = torch.load(path2weights_gen)\n",
        "model_gen.load_state_dict(weights)\n",
        "\n",
        "# evalutaion mode\n",
        "model_gen.eval()\n",
        "\n",
        "# fake image 생성\n",
        "with torch.no_grad():\n",
        "    fixed_noise = torch.randn(1, 100,1,1, device=device)\n",
        "    label = torch.randint(0,10,(16,), device=device)\n",
        "    img_fake = model_gen(fixed_noise).detach().cpu()\n",
        "print(img_fake.shape)"
      ],
      "metadata": {
        "id": "YQUo3J8vZuby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    fixed_noise  = torch.randn(16,100,1,1, device = device)\n",
        "    img_fake = model_gen(fixed_noise).detach().cpu()\n",
        "print(img_fake.shape)"
      ],
      "metadata": {
        "id": "HPDX4T2ZjPxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "이 코드에서 img_fake에 대해 0.5를 곱하고 0.5를 더하는 것은 이미지의 픽셀 값 범위를 조절하는 목적을 가지고 있습니다.\n",
        "\n",
        "GAN의 생성된 이미지는 보통 -1에서 1 사이의 값으로 정규화되어 있습니다. 이는 GAN이 -1부터 1까지의 범위에서 픽셀 값을 생성하도록 훈련되었기 때문입니다. 하지만 대부분의 이미지 시각화 도구 및 라이브러리는 0에서 1의 범위의 값으로 픽셀 값을 기대합니다.\n",
        "\n",
        "따라서 0.5*img_fake + 0.5는 생성된 이미지의 픽셀 값을 -1에서 1의 범위에서 0에서 1의 범위로 변환하여 시각화를 수행하기 위한 것입니다. 이 작업을 통해 이미지를 정확한 범위로 변환하여 시각화할 수 있게 됩니다"
      ],
      "metadata": {
        "id": "qZTYPbQejyRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(to_pil_image(0.5*img_fake[0] + 0.5), cmap = 'gray')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "MVVvu5X4jnCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X4D2RMEOj6jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가짜 이미지 시각화\n",
        "plt.figure(figsize=(10,10))\n",
        "for ii in range(16):\n",
        "    plt.subplot(4,4,ii+1)\n",
        "    plt.imshow(to_pil_image(0.5*img_fake[ii]+0.5), cmap='gray')\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "DqxGIyIHZwdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_epochs = 100\n",
        "\n",
        "for epoch in range(add_epochs):\n",
        "    for xb in dataloader:\n",
        "        ba_si = xb.shape[0]\n",
        "\n",
        "        xb = xb.to(device)\n",
        "        yb_real = torch.Tensor(ba_si,1).fill_(1.0).to(device)\n",
        "        yb_fake = torch.Tensor(ba_si,1).fill_(0.0).to(device)\n",
        "\n",
        "        # generator\n",
        "        model_gen.zero_grad()\n",
        "        z = torch.randn(ba_si,nz,1,1).to(device) # noise\n",
        "        out_gen = model_gen(z) # 가짜 이미지 생성\n",
        "        out_dis = model_dis(out_gen) # 가짜 이미지 식별\n",
        "\n",
        "        g_loss = loss_func(out_dis,yb_real)\n",
        "        g_loss.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "        # discriminator\n",
        "        model_dis.zero_grad()\n",
        "        out_dis = model_dis(xb) # 진짜 이미지 식별\n",
        "        loss_real = loss_func(out_dis,yb_real)\n",
        "\n",
        "        out_dis = model_dis(out_gen.detach()) # 가짜 이미지 식별\n",
        "        loss_fake = loss_func(out_dis,yb_fake)\n",
        "\n",
        "        d_loss = (loss_real + loss_fake) / 2\n",
        "        d_loss.backward()\n",
        "        opt_dis.step()\n",
        "\n",
        "        loss_hist['gen'].append(g_loss.item())\n",
        "        loss_hist['dis'].append(d_loss.item())\n",
        "\n",
        "        batch_count += 1\n",
        "        if batch_count % 64 == 0:\n",
        "            print('Epoch: %.0f, G_Loss: %.6f, D_Loss: %.6f, time: %.2f min' %(epoch, g_loss.item(), d_loss.item(), (time.time()-start_time)/60))"
      ],
      "metadata": {
        "id": "hf48ExjBbBA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCGAN은 입력 image의 크기를 64 x 64로 crop해서 사용하잖아. 만약 입력 input의 크기를 늘린다면, 생성 이미지의 화질 증가에 도움이 될까?\n",
        "\n",
        "ChatGPT\n",
        "일반적으로 DCGAN과 같은 GAN 모델은 고정된 입력 이미지 크기를 사용합니다. 입력 이미지의 크기를 늘리는 것이 항상 화질을 향상시킬 것이라고 단언하기는 어렵습니다. 큰 입력 이미지 크기는 몇 가지 고려해야 할 측면이 있습니다:\n",
        "\n",
        "계산 비용: 큰 입력 이미지 크기는 더 많은 계산 비용을 필요로 합니다. 모델의 파라미터와 메모리 사용량이 늘어날 뿐만 아니라, 학습 및 생성에 더 많은 리소스가 필요합니다.\n",
        "\n",
        "데이터의 다양성: 큰 입력 이미지는 더 다양한 특징을 포함할 수 있습니다. 그러나 이것이 항상 더 나은 결과를 가져다주지는 않습니다. 작은 크기의 이미지에서도 충분히 복잡한 패턴을 학습할 수 있기 때문입니다.\n",
        "\n",
        "모델 복잡성: 더 큰 입력 이미지는 일반적으로 더 복잡한 모델을 필요로 합니다. 따라서 모델의 복잡성을 증가시키면서도 안정적인 학습이 보장되어야 합니다.\n",
        "\n",
        "적절한 해상도 선택: 생성하려는 이미지의 용도에 따라 적절한 입력 이미지 해상도를 선택해야 합니다. 예를 들어, 작은 이미지에서 세부적인 구조를 보고 싶다면 큰 입력 이미지가 필요할 수 있습니다.\n",
        "\n",
        "화질을 높이기 위해서는 위의 문제들을 고려하면서 적절한 trade-off를 찾아야 합니다. 실험을 통해 최적의 설정을 찾고, 필요한 경우에는 모델이나 데이터를 조정하여 화질을 향상시킬 수 있습니다."
      ],
      "metadata": {
        "id": "NIQrDXCdlHMH"
      }
    }
  ]
}